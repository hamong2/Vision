# -*- coding: utf-8 -*-
"""ML_Team_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UQFcfiVzc_tgoET1JM14ZxBvwxJlcAU8

# 1. Introduction

## Simple CNN model for MNIST Dataset

In order to compare the MNIST dataset with Sports dataset, we trained same simple CNN model for both datasets.
"""

import numpy as np
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt

(X_train,y_train),(X_test,y_test)=mnist.load_data()

X_train=np.reshape(X_train,(-1,28,28,1))
X_test=np.reshape(X_test,(-1,28,28,1))

X_train=X_train/255.
X_test=X_test/255.

y_train=to_categorical(y_train)
y_test=to_categorical(y_test)

from tensorflow.keras.layers import Conv2D, MaxPooling2D,Flatten,Dense,Dropout
from tensorflow.keras.models import Sequential

mnist_model=Sequential()
mnist_model.add(Conv2D(16,(3,3),activation='relu',input_shape=(28,28,1),padding='same'))
mnist_model.add(Conv2D(16,(3,3),activation='relu',padding='same'))
mnist_model.add(MaxPooling2D((2,2), strides=2))
mnist_model.add(Dropout(0.2))
mnist_model.add(Conv2D(32,(3,3),activation='relu'))
mnist_model.add(Dropout(0.2))
mnist_model.add(Conv2D(32,(3,3),activation='relu'))
mnist_model.add(MaxPooling2D((2,2), strides=2))
mnist_model.add(Dropout(0.3))
mnist_model.add(Flatten())
mnist_model.add(Dense(64,activation='relu'))
mnist_model.add(Dropout(0.4))
mnist_model.add(Dense(10,activation='softmax'))

mnist_model.summary()

mnist_model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['acc'])
result=mnist_model.fit(X_train,y_train,batch_size=32,epochs=10,validation_split=0.1)

mnist_model.evaluate(X_test, y_test)

"""Test accuracy for this simple CNN model with MNIST dataset is almost 100%!

## Simple CNN model for Sports Dataset
"""

import pandas as pd
import tensorflow as tf
from skimage import io 
import os
from tensorflow.keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array
from tensorflow.keras.metrics import categorical_crossentropy

train_dir='/Users/shin1/Desktop/뇌및머신러닝/team_project/archive/train'
test_dir='/Users/shin1/Desktop/뇌및머신러닝/team_project/archive/test'
validation_dir='/Users/shin1/Desktop/뇌및머신러닝/team_project/archive/valid'

from pathlib import Path
train_path = Path(train_dir)
train_path.glob(r'**/*.jpg')

valid_path = Path(validation_dir)
valid_path.glob(r'**/*.jpg')

test_path = Path(test_dir)
test_path.glob(r'**/*.jpg')

train_filepath = list(train_path.glob(r'**/*.jpg'))
valid_filepath = list(valid_path.glob(r'**/*.jpg'))
test_filepath = list(test_path.glob(r'**/*.jpg'))

classes_train = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],train_filepath))
classes_valid = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],valid_filepath))
classes_test = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],test_filepath))

train_df = pd.concat([pd.Series(train_filepath).astype(str), pd.Series(classes_train)], axis=1)
train_df.columns = ['Images', 'Image_label']

test_df = pd.concat([pd.Series(test_filepath).astype(str), pd.Series(classes_test)], axis=1)
test_df.columns = ['Images', 'Image_label']

valid_df = pd.concat([pd.Series(valid_filepath).astype(str), pd.Series(classes_valid)], axis=1)
valid_df.columns = ['Images', 'Image_label']

print(train_df.shape[0])

X_train=[]
y_train=[]
img_label=0
old_label='lacrosse'
except_idx=[]

for i in range(train_df.shape[0]):
    try:
        image=io.imread(train_df.loc[i]['Images'])
        if (image.shape==(224,224,3)):
            X_train.append(image)
            
            label=train_df.loc[i]['Image_label']
            if label==old_label:
                y_train.append(img_label)
            else:
                img_label+=1
                y_train.append(img_label)
            old_label=train_df.loc[i]['Image_label']
        else:
            except_idx.append(i)
    except:
        continue

"""For train set, if shape of the image is (224,224,3), append the image to X_train and image label to y_train. 

If shape of the image is not (224,224,3), append the image except_idx to discard it.
"""

print(except_idx)

plt.imshow(io.imread(train_df.loc[1663]['Images']))
plt.show()
print(io.imread(train_df.loc[1663]['Images']).shape)

"""This image has only one channel and other images in except_idx have some problems to use in train stage. So we will discard it."""

train_df = train_df.drop(except_idx)

X_train = np.array(X_train)
X_train = X_train.astype('float32')/255.
print(X_train.shape)

"""Normalize X_train. The shape of X_train is (10407, 224, 224, 3) since 9 images were discarded."""

print(len(np.unique(y_train)))

"""y_train has 73 classes to classify."""

from tensorflow.keras.utils import to_categorical

y_train=to_categorical(y_train)
print(y_train.shape)

"""To use in train stage, transfer y_train to one hot encoding."""

X_val=[]
y_val=[]
img_label=0
old_label='lacrosse'
except_idx=[]

for i in range(valid_df.shape[0]):
    try:
        image=io.imread(valid_df.loc[i]['Images'])
        if (image.shape==(224,224,3)):
            X_val.append(image)
            
            label=valid_df.loc[i]['Image_label']
            if label==old_label:
                y_val.append(img_label)
            else:
                img_label+=1
                y_val.append(img_label)
            old_label=valid_df.loc[i]['Image_label']
        else:
            except_idx.append(i)
    except:
        continue

X_val = np.array(X_val)
X_val = X_val.astype('float32')/255.

y_val=to_categorical(y_val)

valid_df = valid_df.drop(except_idx)

"""Do the same thing in validation set."""

X_test=[]
y_test=[]
img_label=0
old_label='lacrosse'
except_idx=[]

for i in range(test_df.shape[0]):
    try:
        image=io.imread(test_df.loc[i]['Images'])
        if (image.shape==(224,224,3)):
            X_test.append(image)
            
            label=test_df.loc[i]['Image_label']
            if label==old_label:
                y_test.append(img_label)
            else:
                img_label+=1
                y_test.append(img_label)
            old_label=test_df.loc[i]['Image_label']
        else:
            except_idx.append(i)
    except:
        continue

X_test = np.array(X_test)
X_test = X_test.astype('float32')/255.

y_test=to_categorical(y_test)

test_df = test_df.drop(except_idx)

"""Also in test set.

Next, we will train the same simple CNN model with above. We changed input_shape and output_shape only.
"""

from tensorflow.keras.layers import Conv2D, MaxPooling2D,Flatten,Dense,Dropout
from tensorflow.keras.models import Sequential

mnist_model=Sequential()
mnist_model.add(Conv2D(16,(3,3),activation='relu',input_shape=(224,224,3),padding='same'))
mnist_model.add(Conv2D(16,(3,3),activation='relu',padding='same'))
mnist_model.add(MaxPooling2D((2,2), strides=2))
mnist_model.add(Dropout(0.2))
mnist_model.add(Conv2D(32,(3,3),activation='relu'))
mnist_model.add(Dropout(0.2))
mnist_model.add(Conv2D(32,(3,3),activation='relu'))
mnist_model.add(MaxPooling2D((2,2), strides=2))
mnist_model.add(Dropout(0.3))
mnist_model.add(Flatten())
mnist_model.add(Dense(64,activation='relu'))
mnist_model.add(Dropout(0.4))
mnist_model.add(Dense(73,activation='softmax'))

mnist_model.summary()

mnist_model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['acc'])
result_mnist=mnist_model.fit(X_train,y_train,batch_size=32,epochs=20,validation_data=(X_val,y_val))

mnist_model.evaluate(X_test, y_test)

import matplotlib.pyplot as plt

accuracy=result_mnist.history['acc']
accuracy_val=result_mnist.history['val_acc']

plt.clf()
plt.plot(accuracy,'b',label='training acc')
plt.plot(accuracy_val,'b', color='r', label='validation acc' )

plt.title('Training and validation accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()
plt.show()

"""This simple CNN model has vibration with validation accuracy and not converges to some value when epoch goes on. Also, it's accuracy is too low for both validation, test set. That means this model is not a good model for this dataset.

# 2. Data preprocessing
"""

# accessing an image file from the dataset classes
image = io.imread(train_df["Images"][0])  

# plotting the original image
i, (im1) = plt.subplots(1)
i.set_figwidth(15)
im1.imshow(image)

# plotting the original image and the RGB channels  

i, (im1, im2, im3, im4) = plt.subplots(1, 4, sharey=True)
i.set_figwidth(20) 

im1.imshow(image)  #Original image
im2.imshow(image[:, : , 0]) #Red
im3.imshow(image[:, : , 1]) #Green
im4.imshow(image[:, : , 2]) #Blue
i.suptitle('Original & RGB image channels')

import skimage
# Grayscale conversion
gray_image = skimage.color.rgb2gray(image)
plt.imshow(gray_image, cmap = 'gray')

# Normalization
norm_image = (gray_image - np.min(gray_image)) / (np.max(gray_image) - np.min(gray_image))
plt.imshow(norm_image)

## Data augmentation

# Shifting
# import libraries

from numpy import expand_dims
from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from keras.preprocessing.image import ImageDataGenerator

# convert to numpy array
data = img_to_array(image)

# expand dimension to one sample
samples = expand_dims(image, 0)

# create image data augmentation generator
datagen = ImageDataGenerator(width_shift_range=[-75,75])

# create an iterator
it = datagen.flow(samples, batch_size=1)
fig, im = plt.subplots(nrows=1, ncols=3, figsize=(15,15))

# generate batch of images
for i in range(3):

    # convert to unsigned integers
    shifted_image = next(it)[0].astype('uint8')
 
    # plot image
    im[i].imshow(shifted_image)

# Flipping
# ImageDataGenerator for flipping
datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)
# expand dimension to one sample
samples = expand_dims(image, 0)
# create an iterator
it = datagen.flow(samples, batch_size=1)
fig, im = plt.subplots(nrows=1, ncols=3, figsize=(15,15))

# generate batch of images
for i in range(3):

    # convert to unsigned integers
    flipped_image = next(it)[0].astype('uint8')
 
    # plot image
    im[i].imshow(flipped_image)

# Rotating
datagen = ImageDataGenerator(rotation_range=20, fill_mode='nearest')
# expand dimension to one sample
samples = expand_dims(image, 0)
# create an iterator
it = datagen.flow(samples, batch_size=1)
fig, im = plt.subplots(nrows=1, ncols=3, figsize=(15,15))

# generate batch of images
for i in range(3):

    # convert to unsigned integers
    rotated_image = next(it)[0].astype('uint8')
 
    # plot image
    im[i].imshow(rotated_image)

# Change brightness
datagen = ImageDataGenerator(brightness_range=[0.5,2.0])
# expand dimension to one sample
samples = expand_dims(image, 0)
# create an iterator
it = datagen.flow(samples, batch_size=1)
fig, im = plt.subplots(nrows=1, ncols=3, figsize=(15,15))

# generate batch of images
for i in range(3):

    # convert to unsigned integers
    brightened_image = next(it)[0].astype('uint8')
 
    # plot image
    im[i].imshow(brightened_image)

# Standardization
datagen = ImageDataGenerator(featurewise_center =True, featurewise_std_normalization = True)
# expand dimension to one sample
samples = expand_dims(image, 0)
# create an iterator
it = datagen.flow(samples, batch_size=1)
fig, im = plt.subplots(nrows=1, ncols=3, figsize=(15,15))

# generate batch of images
for i in range(3):

    # convert to unsigned integers
    standardized_image = next(it)[0].astype('uint8')
 
    # plot image
    im[i].imshow(standardized_image)

train_datagen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, 
                                   shear_range = 0.3, zoom_range = 0.3, horizontal_flip = True, vertical_flip =True)
test_datagen = ImageDataGenerator(rescale = 1./255.)

train_gen = train_datagen.flow_from_dataframe(dataframe = train_df,
                                              x_col = 'Images', y_col ='Image_label',
                                              target_size = (50,50), batch_size = 32, 
                                              class_mode = 'categorical', shuffle = True)
val_gen = train_datagen.flow_from_dataframe(valid_df, 
                                            x_col = 'Images', y_col ='Image_label',
                                            target_size=(50,50), batch_size= 32, 
                                            class_mode='categorical', shuffle=True)
test_gen = test_datagen.flow_from_dataframe(test_df,
                                            x_col = 'Images', y_col ='Image_label',
                                            target_size=(50,50), batch_size= 32, 
                                            class_mode='categorical', shuffle=False)

"""## Simple CNN model with preprocessed sports data

To examine the effects of data preprocessing include data augmentation, the model introduced in the introduction step was equally applied to the dataset after preprocessing. 

In order to reduce the parameters to be estimated, the image size of (224,224,3) was changed to (50,50,3) and the model was fitted.
"""

mnist_model=Sequential()
mnist_model.add(Conv2D(16,(3,3),activation='relu',input_shape=(50,50,3),padding='same'))
mnist_model.add(Conv2D(16,(3,3),activation='relu',padding='same'))
mnist_model.add(MaxPooling2D((2,2), strides=2))
mnist_model.add(Dropout(0.2))
mnist_model.add(Conv2D(32,(3,3),activation='relu'))
mnist_model.add(Dropout(0.2))
mnist_model.add(Conv2D(32,(3,3),activation='relu'))
mnist_model.add(MaxPooling2D((2,2), strides=2))
mnist_model.add(Dropout(0.3))
mnist_model.add(Flatten())
mnist_model.add(Dense(64,activation='relu'))
mnist_model.add(Dropout(0.4))
mnist_model.add(Dense(73,activation='softmax'))

mnist_model.summary()

mnist_model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['acc'])

result_mnist=mnist_model.fit(train_gen, epochs=50, validation_data=val_gen)

mnist_model.evaluate(test_gen)

import matplotlib.pyplot as plt

accuracy=result_mnist.history['acc']
accuracy_val=result_mnist.history['val_acc']

plt.clf()
plt.plot(accuracy,'b',label='training acc')
plt.plot(accuracy_val,'b', color='r', label='validation acc' )

plt.title('Training and validation accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()
plt.show()

"""# 3. Model

## Transfer learning(MobilenetV2)
"""

train_gen = train_datagen.flow_from_dataframe(dataframe = train_df,
                                              x_col = 'Images', y_col ='Image_label',
                                              target_size = (224,224), batch_size = 128, 
                                              class_mode = 'categorical', shuffle = True)
val_gen = train_datagen.flow_from_dataframe(valid_df, 
                                            x_col = 'Images', y_col ='Image_label',
                                            target_size=(224,224), batch_size= 128, 
                                            class_mode='categorical', shuffle=True)
test_gen = test_datagen.flow_from_dataframe(test_df,
                                            x_col = 'Images', y_col ='Image_label',
                                            target_size=(224,224), batch_size= 128, 
                                            class_mode='categorical', shuffle=False)

from tensorflow.keras.applications import MobileNetV2
mobilenet_base = MobileNetV2(input_shape=(224,224,3),
                             include_top=False,
                             weights='imagenet')
mobilenet_base.summary()

mobilenet_base.trainable=False

from tensorflow.keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dropout, GlobalMaxPooling2D, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Model

inputs = Input(shape=(224, 224, 3))
x = mobilenet_base(inputs, training=False)
x = Dense(1024,activation='relu')(x)
x = Dropout(0.4)(x)
x = BatchNormalization()(x)
x = GlobalAveragePooling2D()(x)
x = Dropout(0.2)(x)
outputs = Dense(73, activation='softmax')(x)

mobilenet_model = Model(inputs, outputs)
mobilenet_model.summary()

from tensorflow.keras.utils import plot_model
plot_model(mobilenet_model, show_shapes=True, show_layer_names=True, to_file='model.png')
from IPython.display import Image
Image(retina=True, filename='model.png')

import datetime

log_dir = "logs/my_board/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)

from tensorflow.keras.callbacks import ModelCheckpoint
checkpoint_cb = ModelCheckpoint("model.h5",save_best_only=True)

mobilenet_model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['acc'])
history = mobilenet_model.fit(train_gen, epochs=30, callbacks=[checkpoint_cb,tensorboard_callback], validation_data=val_gen)

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir {log_dir}

mobilenet_model.evaluate(test_gen)

import matplotlib.pyplot as plt
acc=history.history['acc']
val_acc=history.history['val_acc']

plt.clf()
plt.plot(acc,'b',label='training acc')
plt.plot(val_acc,'b', color='r', label='validation acc' )

plt.title('Training and validation accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()
plt.show()

"""## ResNet50V2"""

from tensorflow.keras.applications import ResNet50V2

resnetv2 = ResNet50V2(include_top=False,input_shape=(224,224,3))

for layer in resnetv2.layers:
    layer.trainable = False

resnetv2_model = Sequential([
                             resnetv2,
                             Dense(1024,activation='relu'),
                             Dropout(0.4),
                             BatchNormalization(),
                             GlobalAveragePooling2D(),
                             Dense(73,activation='softmax')
])

from tensorflow.keras.utils import plot_model
plot_model(resnetv2_model, show_shapes=True, show_layer_names=True, to_file='model.png')
from IPython.display import Image
Image(retina=True, filename='model.png')

import datetime

log_dir = "logs/my_board/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)

import keras
checkpoint_cb = keras.callbacks.ModelCheckpoint("model.h5",save_best_only=True)

resnetv2_model.summary()
resnetv2_model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])
history = resnetv2_model.fit(train_gen, epochs = 30, validation_data= val_gen, callbacks=[checkpoint_cb,tensorboard_callback])

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir {log_dir}

import matplotlib.pyplot as plt
acc=history.history['accuracy']
val_acc=history.history['val_accuracy']

plt.clf()
plt.plot(acc,'b',label='training acc')
plt.plot(val_acc,'b', color='r', label='validation acc' )

plt.title('Training and validation accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()
plt.show()

resnetv2_model.evaluate(test_gen)

